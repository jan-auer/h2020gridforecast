---
title: "H2020: Exploratory data analysis of target data"
author: "Jakob Etzel"
date: "26 Feb 2018"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lubridate)
library(knitr)
library(randomcoloR)
library(rje)
library(reshape2)
library(dplyr)
library(ggplot2)
library(h2020gridforecast)
library(xts)
library(dygraphs)
train_all <- readRDS(file = "../../../local_data/train_all.rds")
adapt_all <- readRDS(file = "../../../local_data/adapt_all.rds")
recalculate <- FALSE
```

Format/extension: h5.
The data sets contain 5 min flow-related measurements of high-tension power lines. All together, there are 1916 time series in both data sets. The geolocations of these measurements are not included. Measurements have a sign and it can be different within a time series. This indeed happens for 1141 power lines within just the adapt data set.

The data is a subset of all such lines. In upcoming competition stages, the time increments might vary and time series might have missing values (NaN).

Based on scale and distribution of the values, the measurements are most likely power (load) in MW.

## Train

```{r echo=FALSE}
if (recalculate) {
  column_summaries_train <- data.frame(
    col_name = colnames(train_all), 
    min_val = unlist(lapply(
      colnames(train_all), 
      function (x) min(train_all %>% pull(x), na.rm = TRUE)
    )), 
    max_val = unlist(lapply(
      colnames(train_all), 
      function (x) max(train_all %>% pull(x), na.rm = TRUE)
    )), 
    mean_val = unlist(lapply(
      colnames(train_all), 
      function (x) mean(train_all %>% pull(x), na.rm = TRUE)
    ))
  )
  
  column_summaries_train_long <- melt(column_summaries_train %>% arrange(mean_val), id = "col_name")
  ggplot(
    data = column_summaries_train_long %>% filter(col_name != "timestamp"), 
    aes(x = col_name, y = value, colour = variable)
  ) + geom_point()
  dev.copy(png, 'target_train_statistics.png')
  dev.off()
}
```
Following the minimal, average and maximal value for each power line:
image: ![](target_train_statistics.png)

Choose here a power line ID to see the respective historical measurements.

```{r echo=FALSE}
selectInput(
  inputId = "target_train_column", 
  label = "power line ID:", 
  choices=colnames(train_all %>% select(-timestamp)), 
  selectize = FALSE
)
train_all$datetime = as.POSIXct(train_all$timestamp, origin = "1970-01-01")
```

```{r echo=FALSE}
# renderPlot({
#   plot(
#     sort(train_all$datetime), 
#     train_all %>% 
#       arrange(datetime) %>% 
#       pull(input$target_train_column), 
#     type = "l"
#   )
#   title(main = input$target_train_column)
# })

renderDygraph({
  dygraph(
    xts(
      x = train_all %>% arrange(datetime) %>% pull(input$target_train_column),
      order.by = as.POSIXct(train_all %>% arrange(datetime) %>% pull(datetime), origin = "1970-01-01")
    )
  ) %>% dyRangeSelector()
})
```

### Crosscorrelations
We have a look on how similar power lines are to each other. Therefore we calculate crosscorrelations over the whole train period for every pair of power lines.

```{r echo=FALSE}
if(recalculate) {
  i <- 1916
  grid <- expand.grid(x = 1:i, y = 1:i)
  cors <- matrix(unlist(lapply(
    1:(i*i), 
      function(x) {
        if(grid[x,1] > grid[x,2]) {
          return(cor(train_all %>% pull(grid[x,1]), train_all %>% pull(grid[x,2])))
        } else {
          return(0)
        }
      }
  )), nrow = i)
  saveRDS(object = cors, file = "cors.Rds")
} else {
  cors <- readRDS(file = "cors.Rds")
}

print("pair with max correlation")
which(cors == max(cors, na.rm = TRUE), arr.ind = TRUE)
print("pair with min correlation")
which(cors == min(cors, na.rm = TRUE), arr.ind = TRUE)
```

We print here two power lines which show high negative correlation to each other. It seems as if almost the same load goes through them, but with inversed sign. We can assume that those power lines are indeed running on the same line, but are measured with different directions. If a power line has two or three trunc bundles, it is common to split load evenly between them. The power lines are those with ids 72 and 73.

```{r echo=FALSE}
data <- train_all %>% select(timestamp, 73, 72)
data_long <- melt(data = data, id.vars = 'timestamp')
ggplot(data = data_long, mapping = aes(x = timestamp, y = value, colour = variable)) + geom_line()
```

Here, we show two strongly correlated power lines (94, 96). The graph gives the load of one of them in black and the difference between the two in red.

```{r echo=FALSE}
plot(train_all$`96`, type = "l")
lines(train_all$`96` - train_all$`94`, type="l", col = "red")
```

Here, we show two strongly negative correlated power lines (72, 73). The graph gives the load of one of them in black and the sum of the two in red.

```{r echo=FALSE}
plot(train_all$`72`, type = "l")
lines(train_all$`72` + train_all$`73`, type="l", col = "red")
```

### Spectral densities
```{r echo=FALSE}
selectInput(
  inputId = "target_train_column_spectral", 
  label = "power line ID:", 
  choices=colnames(adapt_all %>% select(-timestamp))
)
selectInput(
  inputId = "spectral_method",
  label = "method: ",
  choices = c("pgram", "ar")
)
```

```{r echo=FALSE}
renderPlot({
  spectrum(train_all %>% pull(input$target_train_column_spectral), method = input$spectral_method)
})
```


### Spectral density with kernel

```{r echo=FALSE}
selectInput(
  inputId = "target_train_column_spectral", 
  label = "power line ID:", 
  choices=colnames(adapt_all %>% select(-timestamp))
)
selectInput(
  inputId = "weights",
  label = "Weights: ",
  choices = c("Bartlett", "trunc", "Tukey")
)
sliderInput(
  inputId = "window_size",
  label = "Window Size: ",
  min= 1L,
  max = 100L,
  value = 20L,
  step = 1L
)
```

```{r echo=FALSE}
renderPlot({
  freqdom::spectral.density(train_all %>% pull(input$target_train_column_spectral), q = input$window_size, weights = input$weights)$freq
})
```

## Adapt
Adapt data is delivered in files of 12 time steps each, i.e. 5 minute resolution of a whole hour.

```{r echo=FALSE}
if (recalculate) {
  column_summaries_adapt <- data.frame(
    col_name = colnames(adapt_all), 
    min_val = unlist(lapply(
      colnames(adapt_all), 
      function (x) min(adapt_all %>% pull(x), na.rm = TRUE)
    )), 
    max_val = unlist(lapply(
      colnames(adapt_all), 
      function (x) max(adapt_all %>% pull(x), na.rm = TRUE)
    )), 
    mean_val = unlist(lapply(
      colnames(adapt_all), 
      function (x) mean(adapt_all %>% pull(x), na.rm = TRUE)
    ))
  )
  
  column_summaries_adapt_long <- melt(column_summaries_adapt %>% arrange(mean_val), id = "col_name")
  ggplot(
    data = column_summaries_adapt_long %>% filter(col_name != "timestamp"), 
    aes(x = col_name, y = value, colour = variable)
  ) + geom_point()
  dev.copy(png, 'target_adapt_statistics.png')
  dev.off()
}
```
Following the minimal, average and maximal value for each power line:
image: ![](target_adapt_statistics.png)

Choose here a power line ID to see the respective historical measurements.

```{r echo=FALSE}
selectInput(
  inputId = "target_adapt_column", 
  label = "power line ID:", 
  choices=colnames(adapt_all %>% select(-timestamp))
)
adapt_all$datetime = as.POSIXct(adapt_all$timestamp, origin = "1970-01-01")
```

```{r echo=FALSE}
renderDygraph({
  dygraph(
    xts(
      x = train_all %>% arrange(datetime) %>% pull(input$target_adapt_column),
      order.by = as.POSIXct(train_all %>% arrange(datetime) %>% pull(datetime), origin = "1970-01-01")
    )
  )
})

```
